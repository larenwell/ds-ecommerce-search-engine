"""
CrossEncoder Retriever for Re-ranking.

Uses a CrossEncoder model to re-rank candidates from a base retriever.
CrossEncoders jointly encode query and document, producing more accurate
relevance scores than bi-encoders at the cost of being slower.

Best for: Re-ranking top-K candidates from fast retriever (BM25).
"""

from typing import List, Optional, Tuple, Dict
import pandas as pd
import numpy as np
from loguru import logger

try:
    from sentence_transformers import CrossEncoder
    CROSSENCODER_AVAILABLE = True
except ImportError:
    CROSSENCODER_AVAILABLE = False
    logger.warning("sentence-transformers not available")

from .base import BaseRetriever
from .bm25 import BM25Retriever
from ..config import config


class CrossEncoderRetriever(BaseRetriever):
    """
    CrossEncoder-based re-ranking retriever.
    
    Strategy:
    1. Get candidates from fast base retriever (BM25)
    2. Score each (query, document) pair with CrossEncoder
    3. Re-rank by scores and return top-k
    
    Advantages:
    - Very accurate (state-of-the-art for re-ranking)
    - No training required (use pre-trained models)
    - Joint encoding captures query-document interaction
    - Significant improvement over BM25 alone (MAP +10-15%)
    
    Trade-offs:
    - Slower than bi-encoders (must encode each pair)
    - Not suitable for large collections (use for re-ranking only)
    - Requires candidates from base retriever
    
    Performance:
    - Typical improvement: MAP@10 from 0.36 â†’ 0.40-0.43
    - Re-ranking 50 candidates takes ~500ms on CPU
    
    Example:
        >>> retriever = CrossEncoderRetriever(
        ...     model_name='cross-encoder/ms-marco-MiniLM-L-6-v2',
        ...     base_retriever=BM25Retriever(),
        ...     candidate_k=50
        ... )
        >>> retriever.fit(product_df)
        >>> results = retriever.retrieve("comfortable armchair")
    """
    
    def __init__(
        self,
        top_k: int = 10,
        model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2',
        base_retriever: Optional[BaseRetriever] = None,
        candidate_k: int = 50,
        batch_size: int = 32,
        text_fields: Optional[List[str]] = None
    ):
        """
        Initialize CrossEncoder retriever.
        
        Args:
            top_k: Number of final results to return
            model_name: CrossEncoder model from HuggingFace
                Available models:
                - 'cross-encoder/ms-marco-MiniLM-L-6-v2' (fast, good)
                - 'cross-encoder/ms-marco-MiniLM-L-12-v2' (slower, better)
                - 'cross-encoder/ms-marco-electra-base' (best quality)
            base_retriever: Base retriever for candidates (default: BM25)
            candidate_k: Number of candidates to retrieve and re-rank
            batch_size: Batch size for scoring
            text_fields: Product fields to use for text
        """
        super().__init__(top_k)
        
        if not CROSSENCODER_AVAILABLE:
            raise ImportError(
                "sentence-transformers required. "
                "Install with: pip install sentence-transformers"
            )
        
        self.model_name = model_name
        self.candidate_k = candidate_k
        self.batch_size = batch_size
        
        self.text_fields = text_fields or [
            'product_name',
            'product_description'
        ]
        
        # Initialize CrossEncoder
        logger.info(f"Loading CrossEncoder: {model_name}")
        try:
            self.cross_encoder = CrossEncoder(model_name, max_length=512)
            logger.info("CrossEncoder loaded successfully")
        except Exception as e:
            logger.error(f"Error loading CrossEncoder: {e}")
            raise
        
        # Base retriever for getting candidates
        self.base_retriever = base_retriever or BM25Retriever(top_k=candidate_k)
        
        logger.info(
            f"CrossEncoderRetriever initialized: "
            f"model={model_name}, candidate_k={candidate_k}"
        )
    
    def fit(self, product_df: pd.DataFrame) -> 'CrossEncoderRetriever':
        """
        Fit retriever (mainly fits base retriever).
        
        Args:
            product_df: DataFrame with product information
            
        Returns:
            Self for method chaining
        """
        logger.info("Fitting CrossEncoder retriever...")
        
        self._validate_product_df(product_df)
        self.product_df = product_df.copy()
        
        # Fit base retriever
        logger.info("Fitting base retriever for candidate generation...")
        self.base_retriever.fit(product_df)
        
        # Prepare product texts for efficient lookup
        self._prepare_product_texts()
        
        self.is_fitted = True
        logger.info("CrossEncoder retriever fitted successfully")
        
        return self
    
    def _prepare_product_texts(self) -> None:
        """Prepare product texts for efficient retrieval."""
        self.product_texts = {}
        
        available_fields = [
            f for f in self.text_fields if f in self.product_df.columns
        ]
        
        logger.info(f"Preparing texts from fields: {available_fields}")
        
        for _, row in self.product_df.iterrows():
            product_id = row['product_id']
            
            # Combine fields
            text_parts = [
                str(row[field]) for field in available_fields
                if pd.notna(row[field])
            ]
            text = " ".join(text_parts)
            
            # Truncate if too long (CrossEncoder has max length)
            if len(text) > 2000:
                text = text[:2000]
            
            self.product_texts[product_id] = text
        
        logger.debug(f"Prepared {len(self.product_texts)} product texts")
    
    def retrieve(self, query: str, top_k: Optional[int] = None) -> List[int]:
        """
        Retrieve and re-rank products using CrossEncoder.
        
        Args:
            query: Search query
            top_k: Number of results
            
        Returns:
            List of product IDs ranked by CrossEncoder score
        """
        results = self.retrieve_with_scores(query, top_k)
        return [pid for pid, _ in results]
    
    def retrieve_with_scores(
        self,
        query: str,
        top_k: Optional[int] = None
    ) -> List[Tuple[int, float]]:
        """
        Retrieve with CrossEncoder scores.
        
        Args:
            query: Search query
            top_k: Number of results
            
        Returns:
            List of (product_id, score) tuples
        """
        self._validate_fitted()
        
        k = top_k or self.top_k
        
        try:
            # Step 1: Get candidates from base retriever
            logger.debug(
                f"Getting {self.candidate_k} candidates from base retriever"
            )
            
            candidates = self.base_retriever.retrieve(query, self.candidate_k)
            
            if not candidates:
                logger.warning("No candidates from base retriever")
                return []
            
            logger.debug(f"Got {len(candidates)} candidates")
            
            # Step 2: Prepare (query, document) pairs
            pairs = []
            valid_candidates = []
            
            for product_id in candidates:
                if product_id in self.product_texts:
                    pairs.append([query, self.product_texts[product_id]])
                    valid_candidates.append(product_id)
            
            if not pairs:
                logger.warning("No valid pairs to score")
                return []
            
            # Step 3: Score pairs with CrossEncoder
            logger.debug(f"Scoring {len(pairs)} pairs with CrossEncoder...")
            
            scores = self.cross_encoder.predict(
                pairs,
                batch_size=self.batch_size,
                show_progress_bar=False
            )
            
            # Step 4: Sort by score and return top-k
            scored_results = list(zip(valid_candidates, scores))
            scored_results.sort(key=lambda x: x[1], reverse=True)
            
            logger.debug(
                f"Re-ranking complete: top score={scored_results[0][1]:.4f}, "
                f"bottom score={scored_results[-1][1]:.4f}"
            )
            
            return scored_results[:k]
            
        except Exception as e:
            logger.error(f"Error in CrossEncoder retrieval: {e}")
            return []
    
    def fine_tune(
        self,
        train_df: pd.DataFrame,
        val_df: Optional[pd.DataFrame] = None,
        epochs: int = 3,
        warmup_steps: int = 100,
        output_path: str = "./models/crossencoder_finetuned"
    ) -> None:
        """
        Fine-tune CrossEncoder on domain-specific data.
        
        Args:
            train_df: Training data with columns [query, document, score]
            val_df: Validation data (optional)
            epochs: Number of training epochs
            warmup_steps: Warmup steps for learning rate
            output_path: Path to save fine-tuned model
        """
        from sentence_transformers import InputExample
        from torch.utils.data import DataLoader
        
        logger.info(f"Fine-tuning CrossEncoder for {epochs} epochs...")
        
        # Prepare training examples
        train_examples = []
        for _, row in train_df.iterrows():
            train_examples.append(
                InputExample(
                    texts=[row['query'], row['document']],
                    label=float(row['score'])
                )
            )
        
        train_dataloader = DataLoader(
            train_examples,
            shuffle=True,
            batch_size=16
        )
        
        # Prepare validation if provided
        evaluator = None
        if val_df is not None:
            from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator
            
            val_sentences = [
                [row['query'], row['document']]
                for _, row in val_df.iterrows()
            ]
            val_labels = val_df['score'].tolist()
            
            evaluator = CEBinaryClassificationEvaluator.from_input_examples(
                [InputExample(texts=s, label=l) for s, l in zip(val_sentences, val_labels)]
            )
        
        # Train
        self.cross_encoder.fit(
            train_dataloader=train_dataloader,
            evaluator=evaluator,
            epochs=epochs,
            warmup_steps=warmup_steps,
            output_path=output_path,
            show_progress_bar=True
        )
        
        logger.info(f"Fine-tuning complete. Model saved to {output_path}")
    
    def explain_score(
        self,
        query: str,
        product_id: int,
        top_n_tokens: int = 10
    ) -> Dict:
        """
        Explain why a product got its score (basic explanation).
        
        Args:
            query: Search query
            product_id: Product ID to explain
            top_n_tokens: Number of top tokens to show
            
        Returns:
            Dictionary with explanation info
        """
        if product_id not in self.product_texts:
            return {"error": "Product not found"}
        
        product_text = self.product_texts[product_id]
        
        # Get score
        score = self.cross_encoder.predict([[query, product_text]])[0]
        
        # Basic token overlap analysis
        query_tokens = set(query.lower().split())
        product_tokens = set(product_text.lower().split())
        overlap = query_tokens & product_tokens
        
        return {
            "product_id": product_id,
            "score": float(score),
            "query": query,
            "product_text_preview": product_text[:200],
            "token_overlap": list(overlap),
            "overlap_ratio": len(overlap) / len(query_tokens) if query_tokens else 0
        }